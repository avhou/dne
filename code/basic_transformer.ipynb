{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T18:12:18.628708Z",
     "start_time": "2024-03-26T18:12:16.418386Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data dimensions\n",
    "Input dimensions: [batch size, sequence length, 1] <br>\n",
    "Target dimensions: [batch size, forecast length (singlestep)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T18:16:26.886164Z",
     "start_time": "2024-03-26T18:16:26.882039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "model_name = \"scratch\" #used in logging\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "SEQUENCE_SIZE = 30\n",
    "BATCH_SIZE = 64\n",
    "INPUT_DIM= 30 \n",
    "EMBED_SIZE= 512\n",
    "NUM_LAYERS= 4\n",
    "HEADS= 8\n",
    "FORWARD_EXPANSION= 512\n",
    "DROPOUT= 0.2\n",
    "FORECAST_SIZE= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T18:16:27.610992Z",
     "start_time": "2024-03-26T18:16:27.607127Z"
    }
   },
   "outputs": [],
   "source": [
    "### Attention mechanism copied from Aladin Persson\n",
    "### see https://github.com/aladdinpersson/Machine-Learning-Collection/tree/master/ML/Pytorch/more_advanced/transformer_from_scratch\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_size, heads):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.heads = heads\n",
    "        self.head_dim = embed_size // heads\n",
    "\n",
    "        assert (\n",
    "            self.head_dim * heads == embed_size\n",
    "        ), \"Embedding size needs to be divisible by heads\"\n",
    "\n",
    "        self.values = nn.Linear(embed_size, embed_size)\n",
    "        self.keys = nn.Linear(embed_size, embed_size)\n",
    "        self.queries = nn.Linear(embed_size, embed_size)\n",
    "        self.fc_out = nn.Linear(embed_size, embed_size)\n",
    "\n",
    "    def forward(self, values, keys, query, mask):\n",
    "        # Get number of training examples\n",
    "        N = query.shape[0]\n",
    "\n",
    "        value_len, key_len, query_len = values.shape[1], keys.shape[1], query.shape[1]\n",
    "\n",
    "        values = self.values(values)  # (N, value_len, embed_size)\n",
    "        keys = self.keys(keys)  # (N, key_len, embed_size)\n",
    "        queries = self.queries(query)  # (N, query_len, embed_size)\n",
    "\n",
    "        # Split the embedding into self.heads different pieces\n",
    "        values = values.reshape(N, value_len, self.heads, self.head_dim)\n",
    "        keys = keys.reshape(N, key_len, self.heads, self.head_dim)\n",
    "        queries = queries.reshape(N, query_len, self.heads, self.head_dim)\n",
    "\n",
    "        # Einsum does matrix mult. for query*keys for each training example\n",
    "        # with every other training example, don't be confused by einsum\n",
    "        # it's just how I like doing matrix multiplication & bmm\n",
    "\n",
    "        energy = torch.einsum(\"nqhd,nkhd->nhqk\", [queries, keys])\n",
    "        # queries shape: (N, query_len, heads, heads_dim),\n",
    "        # keys shape: (N, key_len, heads, heads_dim)\n",
    "        # energy: (N, heads, query_len, key_len)\n",
    "\n",
    "        # Mask padded indices so their weights become 0\n",
    "        if mask is not None:\n",
    "            energy = energy.masked_fill(mask == 0,  float(-1e+30) if energy.dtype == torch.float32 else -float(1e+4))\n",
    "\n",
    "        # Normalize energy values similarly to seq2seq + attention\n",
    "        # so that they sum to 1. Also divide by scaling factor for\n",
    "        # better stability\n",
    "        attention = torch.softmax(energy / (self.embed_size ** (1 / 2)), dim=3)\n",
    "        # attention shape: (N, heads, query_len, key_len)\n",
    "\n",
    "        out = torch.einsum(\"nhql,nlhd->nqhd\", [attention, values]).reshape(\n",
    "            N, query_len, self.heads * self.head_dim\n",
    "        )\n",
    "        # attention shape: (N, heads, query_len, key_len)\n",
    "        # values shape: (N, value_len, heads, heads_dim)\n",
    "        # out after matrix multiply: (N, query_len, heads, head_dim), then\n",
    "        # we reshape and flatten the last two dimensions.\n",
    "\n",
    "        out = self.fc_out(out)\n",
    "        # Linear layer doesn't modify the shape, final shape will be\n",
    "        # (N, query_len, embed_size)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T18:16:31.585366Z",
     "start_time": "2024-03-26T18:16:31.581998Z"
    }
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_size, heads, dropout, forward_expansion):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attention = SelfAttention(embed_size, heads)\n",
    "        self.norm1 = nn.LayerNorm(embed_size)\n",
    "        self.norm2 = nn.LayerNorm(embed_size)\n",
    "\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(embed_size, forward_expansion * embed_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(forward_expansion * embed_size, embed_size),\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, value, key, query, mask):\n",
    "        attention = self.attention(value, key, query, mask)\n",
    "\n",
    "        # Add skip connection, run through normalization and finally dropout\n",
    "        x = self.dropout(self.norm1(attention + query))\n",
    "        forward = self.feed_forward(x)\n",
    "        out = self.dropout(self.norm2(forward + x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T18:16:39.657997Z",
     "start_time": "2024-03-26T18:16:39.649271Z"
    }
   },
   "outputs": [],
   "source": [
    "### Standard Positional encoding\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.2, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T18:21:05.566787Z",
     "start_time": "2024-03-26T18:21:05.562440Z"
    }
   },
   "outputs": [],
   "source": [
    "### Encoder\n",
    "class TimeSeriesEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        embed_size,\n",
    "        num_layers,\n",
    "        heads,\n",
    "        device,\n",
    "        forward_expansion,\n",
    "        dropout,\n",
    "    ):\n",
    "        \n",
    "        super(TimeSeriesEncoder, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.embed_size = embed_size\n",
    "        self.device = device\n",
    "        \n",
    "        self.feature_embedding = nn.Linear(input_dim, embed_size)\n",
    "        self.pos_embedding = PositionalEncoding(embed_size)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                TransformerBlock(\n",
    "                    embed_size,\n",
    "                    heads,\n",
    "                    dropout=dropout,\n",
    "                    forward_expansion=forward_expansion,\n",
    "                )\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        #print(f\"input shape:{x.shape}\")\n",
    "        feature_embed = self.feature_embedding(x.squeeze())\n",
    "        feature_embed = feature_embed.unsqueeze(1).expand(-1, self.input_dim, -1)\n",
    "        #print(f\"feature_embed shape:{feature_embed.shape}\")\n",
    "        pos_embed = self.pos_embedding(x)\n",
    "        #print(f\"pos_embed shape:{pos_embed.shape}\")\n",
    "        \n",
    "        input_embedding = feature_embed + pos_embed\n",
    "        input_embedding = self.dropout(input_embedding)\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            input_embedding = layer(input_embedding, input_embedding, input_embedding, mask)\n",
    "        \n",
    "        return input_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T18:21:06.898696Z",
     "start_time": "2024-03-26T18:21:06.893129Z"
    }
   },
   "outputs": [],
   "source": [
    "### Decoder\n",
    "class TimeSeriesLinearDecoder(nn.Module):\n",
    "    def __init__(self, embed_size, forecast_size=1):\n",
    "        super(TimeSeriesLinearDecoder, self).__init__()\n",
    "        \n",
    "        self.embed_size = embed_size\n",
    "        self.forecast_size = forecast_size\n",
    "        \n",
    "        self.decoder = nn.Linear(embed_size, forecast_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.decoder(x[:, -1, :])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T18:21:15.834853Z",
     "start_time": "2024-03-26T18:21:15.829461Z"
    }
   },
   "outputs": [],
   "source": [
    "### Transformer\n",
    "class TimeSeriesTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        embed_size,\n",
    "        num_layers,\n",
    "        heads,\n",
    "        device,\n",
    "        forward_expansion,\n",
    "        dropout,\n",
    "        forecast_size=1\n",
    "    ):\n",
    "        super(TimeSeriesTransformer, self).__init__()\n",
    "        \n",
    "        self.encoder = TimeSeriesEncoder(\n",
    "            input_dim,\n",
    "            embed_size,\n",
    "            num_layers,\n",
    "            heads,\n",
    "            device,\n",
    "            forward_expansion,\n",
    "            dropout\n",
    "        )\n",
    "        \n",
    "        self.decoder = TimeSeriesLinearDecoder(\n",
    "            embed_size,\n",
    "            forecast_size\n",
    "        )\n",
    "        \n",
    "    def make_mask(self, x):\n",
    "        seq_length = x.shape[1]\n",
    "        return torch.triu(torch.ones(seq_length, seq_length) * float('-inf'), diagonal=1).to(x.device)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mask = self.make_mask(x)\n",
    "        encoded = self.encoder(x, mask)\n",
    "        decoder = self.decoder(encoded)\n",
    "        \n",
    "        return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T18:21:37.084217Z",
     "start_time": "2024-03-26T18:21:33.022555Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexander/ou/IM1102 - Deep Neural Engineering/github/code/venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "/Users/alexander/ou/IM1102 - Deep Neural Engineering/github/code/venv/lib/python3.12/site-packages/torch/cuda/amp/grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = TimeSeriesTransformer(\n",
    "    input_dim=INPUT_DIM, \n",
    "    embed_size=EMBED_SIZE, \n",
    "    num_layers=NUM_LAYERS, \n",
    "    heads=HEADS, \n",
    "    device=device, \n",
    "    forward_expansion=FORWARD_EXPANSION, \n",
    "    dropout=DROPOUT, \n",
    "    forecast_size=FORECAST_SIZE #sigle step forecasting\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "num_epochs = 100\n",
    "save_interval = int(num_epochs * 0.02)\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler() #Quantize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T18:21:44.875849Z",
     "start_time": "2024-03-26T18:21:44.868505Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, device, optimizer, criterion, scaler):\n",
    "    model.train()\n",
    "    train_loss_batch = []\n",
    "    for batch in train_loader:\n",
    "        x_batch, y_batch = batch\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(x_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        train_loss_batch.append(loss.item())\n",
    "    \n",
    "    avg_train_loss = np.mean(train_loss_batch)\n",
    "    return avg_train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T18:21:47.401065Z",
     "start_time": "2024-03-26T18:21:47.393214Z"
    }
   },
   "outputs": [],
   "source": [
    "def validate(model, val_loader, device, criterion):\n",
    "    model.eval()\n",
    "    val_loss_batch = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x_batch, y_batch = batch\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(x_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            val_loss_batch.append(loss.item())\n",
    "    \n",
    "    avg_val_loss = np.mean(val_loss_batch)\n",
    "    return avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T18:22:03.012635Z",
     "start_time": "2024-03-26T18:22:02.969040Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m val_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 9\u001b[0m     avg_train_loss \u001b[38;5;241m=\u001b[39m train_one_epoch(model, \u001b[43mtrain_loader\u001b[49m, device, optimizer, criterion, scaler)\n\u001b[1;32m     10\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(avg_train_loss)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m avg_train_loss \u001b[38;5;241m<\u001b[39m min_train_loss:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "min_train_loss = float('inf')\n",
    "min_val_loss = float('inf')\n",
    "best_model_state = None\n",
    "early_stop_count = 0\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    avg_train_loss = train_one_epoch(model, train_loader, device, optimizer, criterion, scaler)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    \n",
    "    if avg_train_loss < min_train_loss:\n",
    "        min_train_loss = avg_train_loss\n",
    "        best_model_state = {\n",
    "            \"state_dict\": model.state_dict(),\n",
    "            \"epoch\": epoch,\n",
    "            \"type\": \"train\"\n",
    "        }\n",
    "        print(f\"New best training score at epoch {epoch+1}\")\n",
    "\n",
    "    avg_val_loss = validate(model, val_loader, device, criterion)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    \n",
    "    if avg_val_loss < min_val_loss:\n",
    "        min_val_loss = avg_val_loss\n",
    "        best_model_state = {\n",
    "            \"state_dict\": model.state_dict(),\n",
    "            \"epoch\": epoch,\n",
    "            \"type\": \"val\"\n",
    "        }\n",
    "        print(f\"New best validation score at epoch {epoch+1}\")\n",
    "        \n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    if avg_val_loss >= min_val_loss:\n",
    "        early_stop_count += 1\n",
    "        if early_stop_count >= 5:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "    else:\n",
    "        early_stop_count = 0\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {train_losses[-1]:.4f}, Validation Loss: {val_losses[-1]:.4f}\")\n",
    "\n",
    "if best_model_state:\n",
    "    model_type = \"train\" if best_model_state[\"type\"] == \"train\" else \"val\"\n",
    "    torch.save(best_model_state[\"state_dict\"], f'./weights/{model_name}_model_best_{model_type}.pth')\n",
    "    print(f\"Best {model_type} model saved from epoch {best_model_state['epoch']+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Losses Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(f'./graphs/{model_name}_losses_over_epochs.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing\n",
    "model.eval()\n",
    "losses = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        x_batch, y_batch = batch\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        outputs = model(x_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "print(f\"Average MSE over batches: {np.mean(losses)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
